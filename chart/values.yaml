nfs-server-provisioner:
  persistence:
    enabled: true
    size: 10Gi

ssh:
  enabled: true
  image:
    name: astronomycommons/jupyterhub-ssh
    tag: 0.0.4
  hostname: ssh
  config:
    jump:
      ssh_config:
      sshd_config: 
        PasswordAuthentication: "no"
        ClientAliveInterval: 15
    user:
      ssh_config:
      sshd_config: 
        PasswordAuthentication: "no"
        ClientAliveInterval: 15

  # consistent with rest of the JupyterHub
  admin_users:

mariadb:
  auth:
    rootPassword: root
    username: spark
    password: spark
    database: spark_metastore

  initdbScripts:
    hive-schema.sh: |
      #!/bin/bash
      cd /tmp
      curl -s -O https://raw.githubusercontent.com/apache/hive/rel/release-2.3.6/metastore/scripts/upgrade/mysql/hive-txn-schema-2.3.0.mysql.sql
      curl -s -O https://raw.githubusercontent.com/apache/hive/rel/release-2.3.6/metastore/scripts/upgrade/mysql/hive-schema-2.3.0.mysql.sql
      mysql -P 3306 -uroot -p$MARIADB_ROOT_PASSWORD -e "use $MARIADB_DATABASE; source /tmp/hive-schema-2.3.0.mysql.sql;"

jupyterhub:
  custom:
    host_tag: jupyter
  rbac:
    enabled: true
  hub:
    allowNamedServers: true
    # db:
    #   pvc:
    #     storageClassName: nfs
    extraConfig:
      ssh_config: |
        from z2jh import get_config
        if get_config("custom.host_tag"):
          host_tag = get_config("custom.host_tag")
        else:
          host_tag = "jupyter"
        def modify_pod_hook(spawner, pod):
          pod.spec.subdomain = "notebooks"
          if spawner._expand_user_properties("{servername}"):
            pod.spec.hostname = spawner._expand_user_properties(host_tag + "-{username}-{servername}")
          else:
            pod.spec.hostname = spawner._expand_user_properties(host_tag + "-{username}")
          return pod

        c.KubeSpawner.modify_pod_hook = modify_pod_hook

        c.KubeSpawner.extra_container_config = {
          'ports': [
            {
              'containerPort': 8888,
              'name': 'notebook-port',
              'protocol': 'TCP'
            },
            {
              'containerPort': 22, 
              'name': 'ssh-port', 
              'protocol': 'TCP'
            }
          ]
        }

      run_user_as_root: |
        c.KubeSpawner.uid = 0
        c.Spawner.args.append("--allow-root")
      
      auth: |
        import oauthenticator
        from tornado import gen
        import os, secrets
        from z2jh import get_config
        
        class GitHubOAuthenticatorInjectUser(oauthenticator.github.GitHubOAuthenticator):
          @gen.coroutine
          def authenticate(self, handler, data=None):
            userdict = yield super().authenticate(handler, data)
            return userdict

          @gen.coroutine
          def pre_spawn_start(self, user, spawner):
            """Pass user name and user id to spawner via environment variable"""
            auth_state = yield user.get_auth_state()
            if auth_state:
              if auth_state.get("github_user", None):
                # get GitHub user id
                spawner.environment["NB_UID"] = str(auth_state["github_user"]["id"])
                # pass JupyterHub username as NB_USER 
                spawner.environment["NB_USER"] = str(user.name)
                return

            print("error with auth, setting NB_USER to:", user.name)
            spawner.environment["NB_USER"] = str(user.name)

        if get_config("hub.config.JupyterHub.authenticator_class") == "github":
          print("setting authenticator_class to:", GitHubOAuthenticatorInjectUser)
          c.JupyterHub.authenticator_class = GitHubOAuthenticatorInjectUser

        c.Authenticator.enable_auth_state = True
        
  singleuser:
    image: 
      name: astronomycommons/public-hub-singleuser
      tag: 0.5.0
      pullPolicy: Always
    # assigns the notebook pod the service account called jupyter-spark-serviceaccount in the k8s cluster
    # this service account is created if rbac.enabled is set to true in this Helm chart
    # credentials are mounted in the notebook pod at /var/run/secrets/kubernetes.io/serviceaccount
    # allows Spark (and the user) to access the Kubernetes cluster via the API at https://kubernetes.default.svc:443
    serviceAccountName: jupyter-spark-serviceaccount
    # change permissions on home directory to NB_USER
    extraEnv:
      CHOWN_HOME: "yes"
    storage:
      type: none
      # mount the files spark-defaults.conf and spark-env.sh into the user notebook
      # these alter the start-up behavior of Spark
      extraVolumes:
      - name: "spark-config-volume"
        configMap:
          name: "spark-config"
      # jupyter configurations
      - name: "start-notebook-volume"
        configMap:
          name: "start-notebook.d"
      - name: "before-notebook-volume"
        configMap:
          name: "before-notebook.d"
      # consume the nfs PVC that comes with the genesis helm chart
      - name: "nfs-homes-volume"
        persistentVolumeClaim:
          claimName: "nfs-homes"
      - name: "nfs-code-volume"
        persistentVolumeClaim:
          claimName: "nfs-code"
      - name: "nfs-kernels-volume"
        persistentVolumeClaim:
          claimName: "nfs-kernels"
      - name: "ssh-config-volume"
        configMap:
          name: "ssh-config-map"
      extraVolumeMounts:
      # mount spark configurations from configMap
      # mount spark-defaults.conf to spark-defaults.conf.static
      - name: "spark-config-volume"
        mountPath: "/opt/axs/conf/spark-defaults.conf.static"
        # subPath access the specified file within the config map
        subPath: "spark-defaults.conf"
      # mount spark-env.sh to spark-env.sh.static
      - name: "spark-config-volume"
        mountPath: "/opt/axs/conf/spark-env.sh.static"
        subPath: "spark-env.sh"
      # mount hive-site.xml to hive-site.xml.static
      - name: "spark-config-volume"
        mountPath: "/opt/axs/conf/hive-site.xml.static"
        subPath: "hive-site.xml"
      # mount executor.yaml to executor.yaml.static
      - name: "spark-config-volume"
        mountPath: "/opt/axs/conf/executor.yaml.static"
        subPath: "executor.yaml"
      # mount NFS
      # creates a folder for the user in /home and /home contains all other users
      - name: "nfs-homes-volume"
        mountPath: "/home/{username}"
        # subPath creates a folder within the NFS filesystem for the user
        subPath: "{username}"
      - name: "nfs-homes-volume"
        mountPath: "/home"
      - name: "nfs-code-volume"
        mountPath: "/opt/conda/envs"
      - name: "nfs-kernels-volume"
        mountPath: "/opt/conda/share/jupyter/kernels"
      # jupyter configurations
      - name: "start-notebook-volume"
        mountPath: "/usr/local/bin/start-notebook.d"
      - name: "before-notebook-volume"
        mountPath: "/usr/local/bin/before-notebook.d"
      - name: ssh-config-volume
        subPath: ssh_config_user
        mountPath: /etc/_ssh/ssh_config.d/chart.conf
      - name: ssh-config-volume
        subPath: sshd_config_user
        mountPath: /etc/_ssh/sshd_config.d/chart.conf

spark-defaults.conf:
  000-s3-defaults: |
    spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
    spark.hadoop.fs.s3a.connection.maximum=10000
  000-kubernetes-defaults: |
    spark.submit.deployMode=client
    spark.master=k8s://https://kubernetes.default.svc:443
  000-scheduler-defaults: |
    # scheduling options (batch size, time out)
    spark.kubernetes.allocation.batch.size=100
    spark.scheduler.maxRegisteredResourcesWaitingTime=600s
    spark.scheduler.minRegisteredResourcesRatio=1.0
  000-sql-defaults: |
    spark.sql.execution.arrow.enabled=true
    spark.sql.hive.metastore.sharedPrefixes=com.mysql.jdbc,org.postgresql,com.microsoft.sqlserver,oracle.jdbc,org.apache.derby
  # 000-java-defaults: |
  #   spark.driver.extraJavaOptions -Dderby.system.home=/tmp/derby
  # 000-jar-defaults: |
  #   spark.jars /usr/local/axs/python/axs/AxsUtilities-1.0-SNAPSHOT.jar

spark-env.sh:

start-notebook:
  001-env-vars.sh: |
    export SPARK_PUBLIC_DNS="${PUBLIC_URL}${JUPYTERHUB_SERVICE_PREFIX}proxy/4040/jobs/"
    export JAVA_HOME=$(dirname $(dirname $(readlink -f $(which java))))

  002-spark-defaults.sh: |
    conf_file=$SPARK_HOME/conf/spark-defaults.conf.dynamic
    
    echo "" >> $conf_file
    echo "# 002-spark-defaults" >> $conf_file
    echo "spark.driver.host=$(hostname -i)" >> $conf_file
    echo "spark.kubernetes.executor.container.image=${JUPYTER_IMAGE}" >> $conf_file
    # echo "spark.jars=$(ls -p $SPARK_HOME/python/axs/*jar | xargs echo | sed 's/ /,/g')" >> $conf_file
    prefix=spark.executorEnv
    if [ -n "${NB_USER}" ]; then
      echo "${prefix}.NB_USER ${NB_USER}" >> $conf_file
      # echo "spark.kubernetes.executor.podNamePrefix ${NB_USER}-spark" >> $conf_file
      echo "spark.kubernetes.driver.pod.name jupyter-${NB_USER}" | awk '{print tolower($0)}' >> $conf_file
    fi
    if [ -n "${NB_UID}" ]; then
      echo "${prefix}.NB_UID ${NB_UID}" >> $conf_file
    fi
    echo "${prefix}.JAVA_HOME=${JAVA_HOME}" >> $conf_file

  999-merge-spark-files.sh: |
    merge () {
      file=$1
      static_file="$file.static"
      dynamic_file="$file.dynamic"

      if [ -f "$file" ]; then
        rm -f $file
      fi
      if [ -f "$static_file" ]; then
        cat $static_file >> $file
      fi
      if [ -f "$dynamic_file" ]; then
        echo "" >> $file
        cat $dynamic_file >> $file
      fi
    }

    merge "$SPARK_HOME/conf/spark-defaults.conf"
    merge "$SPARK_HOME/conf/spark-env.sh"
    merge "$SPARK_HOME/conf/hive-site.xml"
    merge "$SPARK_HOME/conf/executor.yaml"

before-notebook:
  001-ssh-setup.sh: |
    echo "Starting SSH setup"
    # load ssh config from NFS
    server_config_dir="/home/admin/ssh/users/$NB_USER"
    user_ssh_dir="/home/$NB_USER/.ssh"
    sudo -u $NB_USER mkdir -p ${user_ssh_dir}
    if [ ! -d ${server_config_dir} ]
    then
      echo "${server_config_dir} does not exist. Creating it and copying over contents of /etc/ssh/"
      # Back up host keys and config to NFS
      mkdir -p ${server_config_dir}
      cp -r /etc/ssh/* ${server_config_dir}/.
    fi
    # remove host keys and config from container
    rm -rf /etc/ssh
    # link to host keys and config on NFS
    ln -s ${server_config_dir} /etc/ssh

    # (re)generate missing host keys
    ssh-keygen -A

    # Set-up public/private keys for user
    if test -f "${user_ssh_dir}/id_rsa"; then
      echo "ssh key-pair already exists"
    else
      echo "creating ssh key-pair"
      sudo -u $NB_USER ssh-keygen -t rsa -q -f "${user_ssh_dir}/id_rsa" -N "" || echo "could not create ssh key pair!"
      cat ${user_ssh_dir}/id_rsa.pub >> ${user_ssh_dir}/authorized_keys
      chown -R $NB_USER:$NB_GID ${user_ssh_dir}
    fi

    # restrict logins to only the notebook user
    if grep "AllowUsers $NB_USER" /etc/ssh/sshd_config 2>&1 > /dev/null; then
      echo "AllowUsers $NB_USER exists in /etc/ssh/sshd_config"
    else
      echo "Adding AllowUsers $NB_USER to /etc/ssh/sshd_config"
      echo "AllowUsers $NB_USER" >> /etc/ssh/sshd_config
    fi

    # add config specified via Helm chart
    if [ -d /etc/_ssh ]; then
        cat /etc/_ssh/ssh_config.d/chart.conf
        cp /etc/_ssh/ssh_config.d/chart.conf /etc/ssh/ssh_config.d/.
        cat /etc/_ssh/sshd_config.d/chart.conf
        cp /etc/_ssh/sshd_config.d/chart.conf /etc/ssh/sshd_config.d/.
    fi

    # ensure /run/sshd
    mkdir -p /run/sshd
    # print sshd config
    echo "sshd config:"
    sshd -T
    # start ssh service
    service ssh start

    # add host key fingerprints to known_hosts
    sudo -u $NB_USER touch ${user_ssh_dir}/known_hosts
    hosts="localhost $(hostname).notebooks ssh"
    for host in ${hosts}; do
      if cat "${user_ssh_dir}/known_hosts" | awk '{print $1}' | grep "${host}" 2>&1 > /dev/null; then
        echo "Host key for ${host} already in ${user_ssh_dir}/known_hosts"
      else
        if nslookup ${host} 2>&1 > /dev/null; then
          echo "Adding host key for ${host} to ${user_ssh_dir}/known_hosts"
          ssh-keyscan ${host} 2> /dev/null >> ${user_ssh_dir}/known_hosts
        else
          echo "Cannot find host ${host}"
        fi
      fi
    done

    # ensure bash shell on login
    chsh -s /bin/bash $NB_USER
  
  002-skel.sh: |
    files=".bash_logout .profile .bashrc"
    for file in ${files}; do
      user_file=/home/${NB_USER}/${file}
      if [ -f ${user_file} ]; then
        echo "${user_file} exists"
      else
        sudo -u $NB_USER cp /etc/skel/${file} ${user_file}
      fi
    done
    
nfs-pvcs:
  nfs:
    name: nfs
  homes:
    name: nfs-homes
  code:
    name: nfs-code
  kernels:
    name: nfs-kernels